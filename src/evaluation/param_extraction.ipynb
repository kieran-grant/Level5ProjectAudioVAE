{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models.spectrogram_vae import SpectrogramVAE\n",
    "from src.utils import audio_to_spectrogram\n",
    "from src.plot_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAFX_NAME = \"mda Ambience\"\n",
    "FORMATTED_DAFX_NAME = DAFX_NAME.split()[-1].lower()\n",
    "NUM_EXAMPLES = 10_000\n",
    "CHECKPOINT = \"/home/kieran/Level5ProjectAudioVAE/src/l5proj_spectrogram_vae/hdx3y4ly/checkpoints/epoch=169-step=35530.ckpt\"\n",
    "CHECKPOINT_ID = CHECKPOINT.split(\"/\")[-3]\n",
    "SAVE_PATH = \"/home/kieran/Level5ProjectAudioVAE/src/evaluation/data/param_extraction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dafx = dafx_from_name(DAFX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'freq_hz': {'min': 0.0, 'max': 16000.0},\n",
       " 'fine_hz': {'min': 0.0, 'max': 100.0},\n",
       " 'feedback': {'min': 0.0, 'max': 100.0}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dafx.param_min_max_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpectrogramVAE(\n",
       "  (encoder_conv): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (mu): Linear(in_features=37152, out_features=128, bias=True)\n",
       "  (log_var): Linear(in_features=37152, out_features=128, bias=True)\n",
       "  (decoder_linear): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=37152, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (decoder_conv): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose2d(8, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SpectrogramVAE.load_from_checkpoint(CHECKPOINT).to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 88/88 [00:00<00:00, 44013.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 88 files for train = 66.89 hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = get_audio_dataset(dafx_from_name('clean'),\n",
    "                            num_examples_per_epoch=NUM_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3772/10000 [00:36<01:05, 95.71it/s] "
     ]
    }
   ],
   "source": [
    "settings = []\n",
    "embeddings = []\n",
    "\n",
    "x = next(iter(dataset))\n",
    "\n",
    "for i in tqdm(range(NUM_EXAMPLES)):\n",
    "    setting = dafx.get_random_parameter_settings()\n",
    "\n",
    "    # Apply setting to audio\n",
    "    y = dafx.apply(x, setting)\n",
    "    y = y.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    X = audio_to_spectrogram(signal=y,\n",
    "                             n_fft=model.hparams.n_fft,\n",
    "                             hop_length=model.hparams.hop_length,\n",
    "                             window_size=model.hparams.window_size).to(DEVICE)\n",
    "\n",
    "    _, _, _, z = model(X)\n",
    "\n",
    "    settings.append(setting.cpu().detach().numpy())\n",
    "    embeddings.append(z.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(embeddings).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = np.array(settings).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = umap.UMAP(n_neighbors=15, min_dist=0.1, metric='euclidean').fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Latent embedding shape: \", data.shape)\n",
    "print(\"Param settings shape: \", settings.shape)\n",
    "print(\"UMAP projection shape: \", emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{SAVE_PATH}/{FORMATTED_DAFX_NAME}_data.npy\", data)\n",
    "np.save(f\"{SAVE_PATH}/{FORMATTED_DAFX_NAME}_settings.npy\", settings)\n",
    "np.save(f\"{SAVE_PATH}/{FORMATTED_DAFX_NAME}_projection.npy\", emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
