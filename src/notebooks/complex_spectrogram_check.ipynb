{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pedalboard.pedalboard import load_plugin\n",
    "\n",
    "from src.dataset.paired_audio_dataset import PairedAudioDataset\n",
    "from src.wrappers.dafx_wrapper import DAFXWrapper\n",
    "from src.wrappers.null_dafx_wrapper import NullDAFXWrapper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "DAFX_FILE = \"/home/kieran/Level5ProjectAudioVAE/src/dafx/mda.vst3\"\n",
    "DAFX_NAME = \"clean\"\n",
    "SAMPLE_RATE = 24_000\n",
    "AUDIO_DIR = \"/home/kieran/Level5ProjectAudioVAE/src/audio\"\n",
    "DATASETS = [\"vctk_24000\", \"musdb18_24000\"]\n",
    "NUM_EXAMPLES = 10_000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "if DAFX_NAME.lower() == \"clean\":\n",
    "    dafx = NullDAFXWrapper()\n",
    "else:\n",
    "    dafx = load_plugin(DAFX_FILE, plugin_name=DAFX_NAME)\n",
    "    dafx = DAFXWrapper(dafx=dafx, sample_rate=SAMPLE_RATE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "def audio_to_spectrogram(signal: torch.Tensor,\n",
    "                         n_fft: int = 4096,\n",
    "                         hop_length: int = 2048,\n",
    "                         window_size: int = 4096,\n",
    "                         return_complex: bool = True):\n",
    "\n",
    "    bs, _, _ = signal.size()\n",
    "\n",
    "    window = torch.nn.Parameter(torch.hann_window(window_size))\n",
    "\n",
    "    if return_complex:\n",
    "        # compute spectrogram of waveform\n",
    "        X = torch.stft(\n",
    "            signal.view(bs, -1),\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            window=window,\n",
    "            return_complex=False,\n",
    "        )\n",
    "\n",
    "        return X.permute(0, 3, 2, 1).detach()\n",
    "\n",
    "    X = torch.stft(\n",
    "            signal.view(bs, -1),\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            window=window,\n",
    "            return_complex=True,\n",
    "        )\n",
    "\n",
    "    X_abs = X.abs().unsqueeze(1).permute(0, 1, 3, 2)\n",
    "\n",
    "    return X_abs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 208/208 [00:00<00:00, 15451.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 208 files for train = 52.51 hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = PairedAudioDataset(\n",
    "    dafx=dafx,\n",
    "    audio_dir=AUDIO_DIR,\n",
    "    subset=\"train\",\n",
    "    input_dirs=DATASETS,\n",
    "    num_examples_per_epoch=NUM_EXAMPLES,\n",
    "    augmentations={},\n",
    "    length=24_000*2.5,\n",
    "    effect_input=False,\n",
    "    effect_output=True,\n",
    "    dummy_setting=True\n",
    ")\n",
    "\n",
    "loader= torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=4,\n",
    "    batch_size=16,\n",
    "    timeout=6000,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex shape:  torch.Size([16, 2, 59, 2049])\n",
      "Non-complex shape:  torch.Size([16, 1, 59, 2049])\n",
      "Real parts equal:  False\n",
      "Imag parts equal:  False\n"
     ]
    }
   ],
   "source": [
    "# for batch in loader:\n",
    "#     x, _ = batch\n",
    "#\n",
    "#     x_spec_complx = audio_to_spectrogram(x, return_complex=True)\n",
    "#     x_spec = audio_to_spectrogram(x, return_complex=False)\n",
    "#\n",
    "#     print(\"Complex shape: \", x_spec_complx.shape)\n",
    "#     print(\"Non-complex shape: \", x_spec.shape)\n",
    "#\n",
    "#     print(\"Real parts equal: \", torch.equal(x_spec_complx[:,0,:,:], x_spec[:,:,:,0]))\n",
    "#     print(\"Imag parts equal: \", torch.equal(x_spec_complx[:,1,:,:], x_spec[:,:,:,1]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:16<00:00, 39.03it/s]\n"
     ]
    }
   ],
   "source": [
    "real_means = []\n",
    "real_stds = []\n",
    "complex_means = []\n",
    "complex_stds = []\n",
    "\n",
    "for batch in tqdm(loader):\n",
    "    x, y = batch\n",
    "\n",
    "    x_spec = audio_to_spectrogram(x, return_complex=True)\n",
    "    y_spec = audio_to_spectrogram(y, return_complex=True)\n",
    "\n",
    "    real_means.append(x_spec[:,0,:,:].mean())\n",
    "    real_stds.append(x_spec[:,0,:,:].std())\n",
    "    complex_means.append(x_spec[:,1,:,:].mean())\n",
    "    complex_stds.append(x_spec[:,1,:,:].std())\n",
    "\n",
    "    real_means.append(y_spec[:,0,:,:].mean())\n",
    "    real_stds.append(y_spec[:,0,:,:].std())\n",
    "    complex_means.append(y_spec[:,1,:,:].mean())\n",
    "    complex_stds.append(y_spec[:,1,:,:].std())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "real_means_np = np.array(real_means)\n",
    "real_stds_np = np.array(real_stds)\n",
    "complex_means_np = np.array(complex_means)\n",
    "complex_stds_np = np.array(complex_stds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "-1.77781e-05"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_means_np.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "data": {
      "text/plain": "1.1515284"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_stds_np.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "data": {
      "text/plain": "7.083435e-08"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_means_np.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "data": {
      "text/plain": "1.1449312"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_stds_np.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
