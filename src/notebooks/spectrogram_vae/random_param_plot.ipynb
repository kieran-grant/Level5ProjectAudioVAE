{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from src.models.spectrogram_vae import SpectrogramVAE\n",
    "from src.utils import audio_to_spectrogram\n",
    "from src.plot_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "sns.set(style='dark')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "DAFX_NAME = \"mda Overdrive\"\n",
    "NUM_EXAMPLES = 10_000\n",
    "CHECKPOINT = \"/home/kieran/Level5ProjectAudioVAE/src/l5proj_spectrogram_vae/hdx3y4ly/checkpoints/epoch=169-step=35530.ckpt\"\n",
    "CHECKPOINT_ID = CHECKPOINT.split(\"/\")[-3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "dafx = dafx_from_name(DAFX_NAME)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "SpectrogramVAE(\n  (encoder_conv): Sequential(\n    (0): Sequential(\n      (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): ReLU()\n      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Sequential(\n      (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): ReLU()\n      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): Sequential(\n      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): ReLU()\n      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): Sequential(\n      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): ReLU()\n      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (mu): Linear(in_features=37152, out_features=128, bias=True)\n  (log_var): Linear(in_features=37152, out_features=128, bias=True)\n  (decoder_linear): Sequential(\n    (0): Linear(in_features=128, out_features=37152, bias=True)\n    (1): ReLU()\n  )\n  (decoder_conv): Sequential(\n    (0): Sequential(\n      (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): ReLU()\n      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Sequential(\n      (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): ReLU()\n      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): Sequential(\n      (0): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): ReLU()\n      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): Sequential(\n      (0): ConvTranspose2d(8, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    )\n  )\n)"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SpectrogramVAE.load_from_checkpoint(CHECKPOINT).to(DEVICE)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 88/88 [00:00<00:00, 638.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 88 files for train = 66.89 hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = get_audio_dataset(dafx_from_name('clean'),\n",
    "                            num_examples_per_epoch=NUM_EXAMPLES)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 3642/10000 [00:37<00:59, 106.40it/s]"
     ]
    }
   ],
   "source": [
    "settings = []\n",
    "embeddings = []\n",
    "\n",
    "x = next(iter(dataset))\n",
    "\n",
    "for i in tqdm(range(NUM_EXAMPLES)):\n",
    "    setting = dafx.get_random_parameter_settings()\n",
    "\n",
    "    # Apply setting to audio\n",
    "    y = dafx.apply(x, setting)\n",
    "    y = y.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    X = audio_to_spectrogram(signal=y,\n",
    "                 n_fft=model.hparams.n_fft,\n",
    "                 hop_length=model.hparams.hop_length,\n",
    "                 window_size=model.hparams.window_size).to(DEVICE)\n",
    "\n",
    "    _, _, _, z = model(X)\n",
    "\n",
    "    settings.append(setting.cpu().detach().numpy())\n",
    "    embeddings.append(z.cpu().detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = np.array(embeddings).squeeze()\n",
    "settings = np.array(settings).squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "emb = umap.UMAP(n_neighbors=15, min_dist=0.1, metric='euclidean').fit_transform(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_data = {dafx.idx_to_param_map[i]: settings[:,i] for i in range(dafx.get_num_params())}\n",
    "df_data.update({\"x\": emb[:, 0], \"y\": emb[:, 1]})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = f\"{CHECKPOINT_ID}_{DAFX_NAME.split()[-1]}_{NUM_EXAMPLES}settings\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "n = dafx.get_num_params() # Define the size of the plot\n",
    "max_columns = 3  # set a maximum number of columns\n",
    "\n",
    "num_rows, num_cols = get_subplot_dimensions(n, max_columns=max_columns)\n",
    "# Create the figure and subplots\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(4*num_cols, 4*num_rows + 2))\n",
    "\n",
    "count = 0\n",
    "for i in range(dafx.get_num_params()):\n",
    "    row_idx, col_idx = divmod(count, num_cols)\n",
    "\n",
    "    if num_rows == 1:\n",
    "            current_ax = axs[col_idx]\n",
    "    elif num_cols == 1:\n",
    "        current_ax = axs[row_idx]\n",
    "    else:\n",
    "        current_ax = axs[row_idx, col_idx]\n",
    "\n",
    "    param_name = dafx.idx_to_param_map[i]\n",
    "\n",
    "    sc = current_ax.scatter(x=df['x'], y=df['y'], c=df[param_name], s=10, alpha=0.7, cmap='magma')\n",
    "\n",
    "    current_ax.set_title(param_name)\n",
    "    current_ax.grid()\n",
    "    current_ax.set_xlabel(\"\")\n",
    "    current_ax.set_ylabel(\"\")\n",
    "    # current_ax.set_aspect('equal', 'datalim')\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    # If we have processed all the subplots, break out of the loop\n",
    "    if count == n:\n",
    "        break\n",
    "\n",
    "fig.suptitle(f\"{DAFX_NAME} {NUM_EXAMPLES} parameter configurations latent space\")\n",
    "\n",
    "# If we have fewer subplots than required, remove the remaining subplots\n",
    "while count < n:\n",
    "    row_idx, col_idx = divmod(count, num_cols)\n",
    "    axs[row_idx, col_idx].remove()\n",
    "    # fig.delaxes()\n",
    "    count += 1\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Add colorbar\n",
    "cbar = fig.colorbar(sc, ax=axs.ravel().tolist(), aspect=20, shrink=.5, pad=.1, orientation='horizontal')\n",
    "cbar.set_label('Parameter value')\n",
    "\n",
    "plt.savefig(f\"./figures/random_param_plot/{EXPERIMENT_NAME}.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
