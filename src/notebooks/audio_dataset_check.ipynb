{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pedalboard.pedalboard import load_plugin\n",
    "\n",
    "from src.dataset.audio_dataset import AudioDataset\n",
    "from src.wrappers.dafx_wrapper import DAFXWrapper\n",
    "from src.wrappers.null_dafx_wrapper import NullDAFXWrapper\n",
    "\n",
    "from src.models.vae import SpectrogramVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "DAFX_FILE = \"/home/kieran/Level5ProjectAudioVAE/src/dafx/mda.vst3\"\n",
    "DAFX_NAME = \"mda MultiBand\"\n",
    "SAMPLE_RATE = 24_000\n",
    "AUDIO_DIR = \"/home/kieran/Level5ProjectAudioVAE/src/audio\"\n",
    "DATASETS = [\"vctk_24000\"]\n",
    "NUM_EXAMPLES = 5\n",
    "MODEL_CHECKPOINT = \"/home/kieran/Level5ProjectAudioVAE/src/l5proj_spectrogram_vae/nbospq83/checkpoints/epoch=140-step=88125.ckpt\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "if DAFX_NAME.lower == \"clean\":\n",
    "    dafx = NullDAFXWrapper()\n",
    "else:\n",
    "    dafx = load_plugin(DAFX_FILE, plugin_name=DAFX_NAME)\n",
    "    dafx = DAFXWrapper(dafx=dafx, sample_rate=SAMPLE_RATE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 88/88 [00:00<00:00, 25820.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 88 files for train = 66.89 hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = AudioDataset(\n",
    "    dafx=dafx,\n",
    "    audio_dir=AUDIO_DIR,\n",
    "    subset=\"train\",\n",
    "    input_dirs=DATASETS,\n",
    "    num_examples_per_epoch=NUM_EXAMPLES,\n",
    "    effect_audio=False,\n",
    "    dummy_setting=True\n",
    ")\n",
    "\n",
    "loader= torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=4,\n",
    "    batch_size=1,\n",
    "    timeout=6000,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Missing attribute \"conv_kernel\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/Level5ProjectAudioVAE/venv/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:289\u001B[0m, in \u001B[0;36mAttributeDict.__getattr__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exp:\n",
      "\u001B[0;31mKeyError\u001B[0m: 'conv_kernel'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mSpectrogramVAE\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_from_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMODEL_CHECKPOINT\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Level5ProjectAudioVAE/venv/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:139\u001B[0m, in \u001B[0;36mModelIO.load_from_checkpoint\u001B[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_from_checkpoint\u001B[39m(\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m     67\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Self:  \u001B[38;5;66;03m# type: ignore[valid-type]\u001B[39;00m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;124;03m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001B[39;00m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;124;03m        y_hat = pretrained_model(x)\u001B[39;00m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 139\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_from_checkpoint\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    140\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    143\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhparams_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    145\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    146\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Level5ProjectAudioVAE/venv/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:188\u001B[0m, in \u001B[0;36m_load_from_checkpoint\u001B[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_state(\u001B[38;5;28mcls\u001B[39m, checkpoint, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    187\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mcls\u001B[39m, pl\u001B[38;5;241m.\u001B[39mLightningModule):\n\u001B[0;32m--> 188\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_state\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnsupported \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Level5ProjectAudioVAE/venv/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:234\u001B[0m, in \u001B[0;36m_load_state\u001B[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001B[0m\n\u001B[1;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m cls_spec\u001B[38;5;241m.\u001B[39mvarkw:\n\u001B[1;32m    231\u001B[0m     \u001B[38;5;66;03m# filter kwargs according to class init unless it allows any argument via kwargs\u001B[39;00m\n\u001B[1;32m    232\u001B[0m     _cls_kwargs \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m _cls_kwargs\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m cls_init_args_name}\n\u001B[0;32m--> 234\u001B[0m obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_cls_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj, pl\u001B[38;5;241m.\u001B[39mLightningModule):\n\u001B[1;32m    237\u001B[0m     \u001B[38;5;66;03m# give model a chance to load something\u001B[39;00m\n\u001B[1;32m    238\u001B[0m     obj\u001B[38;5;241m.\u001B[39mon_load_checkpoint(checkpoint)\n",
      "File \u001B[0;32m~/Level5ProjectAudioVAE/src/models/vae.py:30\u001B[0m, in \u001B[0;36mSpectrogramVAE.__init__\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_dim_enc \u001B[38;5;241m=\u001B[39m prod(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhparams\u001B[38;5;241m.\u001B[39mhidden_dim)\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_dim_dec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhparams\u001B[38;5;241m.\u001B[39mhidden_dim\n\u001B[0;32m---> 30\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Level5ProjectAudioVAE/src/models/vae.py:34\u001B[0m, in \u001B[0;36mSpectrogramVAE._build_model\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_model\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 34\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_encoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_decoder()\n",
      "File \u001B[0;32m~/Level5ProjectAudioVAE/src/models/vae.py:41\u001B[0m, in \u001B[0;36mSpectrogramVAE._build_encoder\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_encoder\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menc_conv1 \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mSequential(\n\u001B[1;32m     39\u001B[0m         nn\u001B[38;5;241m.\u001B[39mConv2d(in_channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhparams\u001B[38;5;241m.\u001B[39mnum_channels,\n\u001B[1;32m     40\u001B[0m                   out_channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m,\n\u001B[0;32m---> 41\u001B[0m                   kernel_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhparams\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv_kernel\u001B[49m,\n\u001B[1;32m     42\u001B[0m                   padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhparams\u001B[38;5;241m.\u001B[39mconv_padding,\n\u001B[1;32m     43\u001B[0m                   stride\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhparams\u001B[38;5;241m.\u001B[39mconv_stride\n\u001B[1;32m     44\u001B[0m                   ),\n\u001B[1;32m     45\u001B[0m         nn\u001B[38;5;241m.\u001B[39mReLU(),\n\u001B[1;32m     46\u001B[0m         nn\u001B[38;5;241m.\u001B[39mBatchNorm2d(\u001B[38;5;241m8\u001B[39m)\n\u001B[1;32m     47\u001B[0m     )\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menc_conv2 \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mSequential(\n\u001B[1;32m     50\u001B[0m         nn\u001B[38;5;241m.\u001B[39mConv2d(in_channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m,\n\u001B[1;32m     51\u001B[0m                   out_channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     57\u001B[0m         nn\u001B[38;5;241m.\u001B[39mBatchNorm2d(\u001B[38;5;241m16\u001B[39m),\n\u001B[1;32m     58\u001B[0m     )\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menc_conv3 \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mSequential(\n\u001B[1;32m     61\u001B[0m         nn\u001B[38;5;241m.\u001B[39mConv2d(in_channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m,\n\u001B[1;32m     62\u001B[0m                   out_channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     68\u001B[0m         nn\u001B[38;5;241m.\u001B[39mBatchNorm2d(\u001B[38;5;241m32\u001B[39m),\n\u001B[1;32m     69\u001B[0m     )\n",
      "File \u001B[0;32m~/Level5ProjectAudioVAE/venv/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:291\u001B[0m, in \u001B[0;36mAttributeDict.__getattr__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m[key]\n\u001B[1;32m    290\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exp:\n\u001B[0;32m--> 291\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing attribute \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mexp\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: Missing attribute \"conv_kernel\""
     ]
    }
   ],
   "source": [
    "model = SpectrogramVAE.load_from_checkpoint(MODEL_CHECKPOINT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
