{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "17c26fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9351e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PARAMS = 5\n",
    "AUDIO_LEN = 131_072\n",
    "NUM_EXAMPLES = 1_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4cffd09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_audio():\n",
    "    return torch.rand(1, AUDIO_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "150b0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_features(x):\n",
    "    return x[0,0].abs().item(), x[0,-1].abs().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8e0e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_settings():\n",
    "    return np.ones(NUM_PARAMS) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9d4dd638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(signal, params):\n",
    "    return signal * params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "66f0b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_embeddings(x, y):\n",
    "    return torch.rand(1, 128), torch.rand(1, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "821bffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_embeddings(z_x, z_y):\n",
    "    # y_hat, p, z\n",
    "    return torch.rand(1, AUDIO_LEN), torch.ones(NUM_PARAMS), torch.concat([z_x, z_y], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2645b1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_audio(signal, f_name):\n",
    "    f_name = f\"./audio{i}.wav\"\n",
    "    return f_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2fb21747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1177.46it/s]\n"
     ]
    }
   ],
   "source": [
    "y_embeddings = []\n",
    "metadata = []\n",
    "\n",
    "x = get_dummy_audio()\n",
    "x_b, x_d = get_audio_features(x)\n",
    "\n",
    "for i in tqdm(range(NUM_EXAMPLES)):\n",
    "    p = get_random_settings()\n",
    "    y = apply(x, p)\n",
    "    \n",
    "    z_x, z_y = get_audio_embeddings(x, y)\n",
    "    \n",
    "    y_hat, p_hat, _ = predict_for_embeddings(z_x, z_y)\n",
    "    \n",
    "    y_hat_b, y_hat_d = get_audio_features(y_hat)\n",
    "    \n",
    "    f_name = save_audio(y_hat, i)   \n",
    "    \n",
    "    data_dict = {\n",
    "        'idx': i,\n",
    "        'audio_file': f_name,\n",
    "        'p': p.tolist(),\n",
    "        'p_hat': p_hat.cpu().detach().tolist(),\n",
    "        'x_b': x_b,\n",
    "        'x_d': x_d,\n",
    "        'y_hat_b': y_hat_b,\n",
    "        'y_hat_d': y_hat_d\n",
    "    }\n",
    "    \n",
    "    y_embeddings.append(z_y.cpu().detach().numpy())\n",
    "    metadata.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "443cb15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 999,\n",
       " 'audio_file': './audio999.wav',\n",
       " 'p': [0.5, 0.5, 0.5, 0.5, 0.5],\n",
       " 'p_hat': [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       " 'x_b': 0.5457613468170166,\n",
       " 'x_d': 0.26437288522720337,\n",
       " 'y_hat_b': 0.13721776008605957,\n",
       " 'y_hat_d': 0.682701587677002}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d56de616",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(y_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "037cfa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.45345825, 0.09091669, 0.14712751, ..., 0.92848897,\n",
       "         0.06354427, 0.7937085 ]],\n",
       "\n",
       "       [[0.13964194, 0.14951897, 0.47155482, ..., 0.8443642 ,\n",
       "         0.8752798 , 0.25924605]],\n",
       "\n",
       "       [[0.7502417 , 0.5776028 , 0.18736202, ..., 0.51862115,\n",
       "         0.6732958 , 0.69785696]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.908244  , 0.162776  , 0.418715  , ..., 0.8724022 ,\n",
       "         0.7061511 , 0.8146104 ]],\n",
       "\n",
       "       [[0.9140881 , 0.75790155, 0.52919185, ..., 0.9824308 ,\n",
       "         0.6462053 , 0.01463723]],\n",
       "\n",
       "       [[0.31213206, 0.61359096, 0.29308003, ..., 0.07543206,\n",
       "         0.5162881 , 0.284436  ]]], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceb781e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
