{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    0: 'drive',\n",
    "    1: 'hpf',\n",
    "    2: 'bias',\n",
    "    3: 'output_db'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PARAMS = len(PARAMS)\n",
    "AUDIO_LEN = 131_072\n",
    "NUM_EXAMPLES = 1_000\n",
    "PATH = \"./data/\"\n",
    "CHECKPOINT_ID = \"TEST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = os.path.join(PATH, CHECKPOINT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/TEST  was created!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(FOLDER):\n",
    "    os.makedirs(FOLDER)\n",
    "    print(FOLDER, \" was created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_audio():\n",
    "    return torch.rand(1, AUDIO_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_features(x):\n",
    "    return x[0,0].abs().item(), x[0,-1].abs().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_settings():\n",
    "    return np.ones(NUM_PARAMS) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(signal, params):\n",
    "    return signal * params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_embeddings(x, y):\n",
    "    return torch.rand(1, 128), torch.rand(1, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_embeddings(z_x, z_y):\n",
    "    # y_hat, p, z\n",
    "    return torch.rand(1, AUDIO_LEN), torch.ones(NUM_PARAMS), torch.concat([z_x, z_y], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_audio(signal, f_name):\n",
    "    f_name = f\"./audio{i}.wav\"\n",
    "    return f_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_param_name(idx):\n",
    "    return PARAMS.get(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_vector_to_named_dictionary(vec, prefix=\"\"):\n",
    "    vec = vec.squeeze()\n",
    "    \n",
    "    if type(vec) == torch.Tensor:\n",
    "        vec = vec.cpu().detach().numpy()\n",
    "        \n",
    "    assert(len(vec.shape) == 1)\n",
    "    \n",
    "    out = {}\n",
    "    \n",
    "    for i in range(len(vec)):\n",
    "        param_name = index_to_param_name(i)\n",
    "        out[f\"{prefix}{param_name}\"] = vec[i]\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 731.17it/s]\n"
     ]
    }
   ],
   "source": [
    "y_embeddings = []\n",
    "metadata = []\n",
    "\n",
    "x = get_dummy_audio()\n",
    "x_b, x_d = get_audio_features(x)\n",
    "\n",
    "for i in tqdm(range(NUM_EXAMPLES)):\n",
    "    p = get_random_settings()\n",
    "    y = apply(x, p)\n",
    "    \n",
    "    z_x, z_y = get_audio_embeddings(x, y)\n",
    "    \n",
    "    y_hat, p_hat, _ = predict_for_embeddings(z_x, z_y)\n",
    "    \n",
    "    y_hat_b, y_hat_d = get_audio_features(y_hat)\n",
    "    \n",
    "    f_name = save_audio(y_hat, i)   \n",
    "    \n",
    "    data_dict = {\n",
    "        'id': i,\n",
    "        'audio_file': f_name,\n",
    "        'x_b': x_b,\n",
    "        'x_d': x_d,\n",
    "        'y_hat_b': y_hat_b,\n",
    "        'y_hat_d': y_hat_d,\n",
    "        'brightness_diff': y_hat_b - x_b,\n",
    "        'depth_diff': y_hat_d - x_d\n",
    "    }\n",
    "    \n",
    "    params = param_vector_to_named_dictionary(p, \"p_\")\n",
    "    params_hat = param_vector_to_named_dictionary(p_hat, \"p_hat_\")\n",
    "    \n",
    "    data_dict.update(params)\n",
    "    data_dict.update(params_hat)\n",
    "    \n",
    "    y_embeddings.append(z_y.cpu().detach().numpy())\n",
    "    metadata.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 999,\n",
       " 'audio_file': './audio999.wav',\n",
       " 'x_b': 0.49158358573913574,\n",
       " 'x_d': 0.3661285638809204,\n",
       " 'y_hat_b': 0.671504020690918,\n",
       " 'y_hat_d': 0.3070797324180603,\n",
       " 'brightness_diff': 0.17992043495178223,\n",
       " 'depth_diff': -0.05904883146286011,\n",
       " 'p_drive': 0.5,\n",
       " 'p_hpf': 0.5,\n",
       " 'p_bias': 0.5,\n",
       " 'p_output_db': 0.5,\n",
       " 'p_hat_drive': 1.0,\n",
       " 'p_hat_hpf': 1.0,\n",
       " 'p_hat_bias': 1.0,\n",
       " 'p_hat_output_db': 1.0}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(y_embeddings).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 128)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metadata).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(FOLDER, \"y_embeddings.npy\"), embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(FOLDER, \"metadata.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
