train_loss/loss,train_loss/recon_loss,train_loss/vq_loss,epoch,step,val_loss/loss,val_loss/recon_loss,val_loss/vq_loss
0.10158094018697739,0.06254968047142029,0.0390312597155571,0,49,,,
0.08788368105888367,0.06157723069190979,0.02630644664168358,0,99,,,
0.0798746719956398,0.06629731506109238,0.013577355071902275,0,149,,,
,,,0,195,0.09454526752233505,0.06189176067709923,0.03265354782342911
0.08860602974891663,0.0628558099269867,0.025750216096639633,1,199,,,
0.09098473191261292,0.06376910954713821,0.0272156223654747,1,249,,,
0.09367019683122635,0.06197621673345566,0.03169398009777069,1,299,,,
0.08730656653642654,0.06049507111310959,0.026811497285962105,1,349,,,
,,,1,391,0.08179276436567307,0.0618496872484684,0.019943058490753174
0.09500561654567719,0.06349252164363861,0.031513091176748276,2,399,,,
0.08159812539815903,0.06217878311872482,0.019419342279434204,2,449,,,
0.09235695749521255,0.06082210689783096,0.03153485059738159,2,499,,,
0.08347071707248688,0.06114029884338379,0.022330421954393387,2,549,,,
,,,2,587,0.09257759898900986,0.06185202673077583,0.030725551769137383
0.08429233729839325,0.06320290267467499,0.021089432761073112,3,599,,,
0.06955903768539429,0.05699034780263901,0.012568686157464981,3,649,,,
0.04989727586507797,0.04326014965772629,0.00663712527602911,3,699,,,
0.026326097548007965,0.021560553461313248,0.004765543155372143,3,749,,,
,,,3,783,0.02526433765888214,0.02026575617492199,0.004998586140573025
